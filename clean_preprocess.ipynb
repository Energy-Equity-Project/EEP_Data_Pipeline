{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning and Preprocessing Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook describes how variables were cleaned for data processing. The output files of this script will go in the clean_data/ folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning Non-Energy Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## American Community Survey (ACS), US Census"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acs = pd.read_csv(\"data/acs/acs_data.csv\", dtype = {\n",
    "   \"STATE\": str,\n",
    "   \"GEOID\": str\n",
    "})\n",
    "\n",
    "# Removing unnecessary variables\n",
    "acs.pop(\"NAME\")\n",
    "acs.pop(\"state\")\n",
    "acs.pop(\"county\")\n",
    "acs.pop(\"tract\")\n",
    "\n",
    "# Estimate for percent BIPOC\n",
    "acs[\"bipoc_percent\"] = (acs[\"white_no_hispanic\"] / acs[\"total_pop\"]) * 100\n",
    "acs[\"bipoc_percent\"] = 100 - acs[\"bipoc_percent\"]\n",
    "acs.pop(\"white_no_hispanic\")\n",
    "\n",
    "# Turn appropriate variables from raw counts to percentages\n",
    "acs[\"internet_access\"] = (acs[\"internet_access\"] / acs[\"total_households\"]) * 100\n",
    "acs[\"no_hs\"] = (acs[\"less_than_hs\"] / acs[\"total_pop\"]) * 100\n",
    "acs.pop(\"less_than_hs\")\n",
    "acs[\"insured\"] = (acs[\"insured\"] / acs[\"total_pop\"]) * 100\n",
    "acs[\"seniors_living_alone\"] = (acs[\"seniors_living_alone\"] / acs[\"total_pop\"]) * 100\n",
    "acs[\"owner_occupied\"] = (acs[\"owner_occupied\"] / acs[\"occupied_housing_units\"]) * 100\n",
    "acs[\"renter_occupied\"] = (acs[\"renter_occupied\"] / acs[\"occupied_housing_units\"]) * 100\n",
    "acs.pop(\"occupied_housing_units\")\n",
    "acs[\"disabled\"] = (acs[\"disabled\"] / acs[\"pop_16_plus\"]) * 100\n",
    "acs.pop(\"pop_16_plus\")\n",
    "\n",
    "acs_num_cols = [\n",
    "   \"total_pop\",\n",
    "   \"year_built\",\n",
    "   \"internet_access\",\n",
    "   \"total_households\",\n",
    "   \"labor_force_rate\",\n",
    "   \"insured\",\n",
    "   \"seniors_living_alone\",\n",
    "   \"median_income\",\n",
    "   \"owner_occupied\",\n",
    "   \"renter_occupied\",\n",
    "   \"disabled\",\n",
    "   \"bipoc_percent\",\n",
    "   \"no_hs\"\n",
    "]\n",
    "\n",
    "for col in acs_num_cols:\n",
    "   acs[col] = np.where(\n",
    "      acs[col] < 0,\n",
    "      np.nan,\n",
    "      acs[col]\n",
    "   )\n",
    "\n",
    "acs.to_csv(\"clean_data/non_energy/acs.csv\", index = False)\n",
    "acs.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Climate Vulnerability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read climate vulnerability with correct column types\n",
    "climate_vulnerability = pd.read_csv(\n",
    "   \"data/climate_vulnerability/NRI_Table_CensusTracts/NRI_Table_CensusTracts.csv\",\n",
    "   dtype = {\n",
    "      \"TRACTFIPS\": str,\n",
    "      \"HRCN_RISKS\": float, \n",
    "      \"HRCN_RISKR\": str,\n",
    "      \"HWAV_RISKS\": float,\n",
    "      \"HWAV_RISKR\": str,\n",
    "      \"WFIR_RISKS\": float,\n",
    "      \"WFIR_RISKR\": str\n",
    "      }\n",
    "   )\n",
    "\n",
    "# Subset and Rename column names\n",
    "climate_vulnerability = climate_vulnerability[[\n",
    "   \"TRACTFIPS\",\n",
    "   \"HRCN_RISKS\",\n",
    "   \"HRCN_RISKR\",\n",
    "   \"HWAV_RISKS\",\n",
    "   \"HWAV_RISKR\",\n",
    "   \"WFIR_RISKS\",\n",
    "   \"WFIR_RISKR\"]]\n",
    "\n",
    "climate_vulnerability.columns = [\n",
    "   \"GEOID\",\n",
    "   \"hurricane_risk_index\",\n",
    "   \"hurricane_risk_rating\",\n",
    "   \"heat_wave_risk_index\",\n",
    "   \"heat_wave_risk_rating\",\n",
    "   \"wild_fire_risk_index\",\n",
    "   \"wild_fire_risk_rating\"\n",
    "   ]\n",
    "\n",
    "# Format GEOID column to have 11 digits, pad with 0s as necessary\n",
    "climate_vulnerability[\"GEOID\"] = np.where(\n",
    "   climate_vulnerability[\"GEOID\"].str.len() == 10,\n",
    "   \"0\" + climate_vulnerability[\"GEOID\"],\n",
    "   climate_vulnerability[\"GEOID\"]\n",
    ")\n",
    "\n",
    "# Write results out\n",
    "climate_vulnerability.to_csv(\"clean_data/non_energy/climate_vulnerability.csv\", index = False)\n",
    "climate_vulnerability.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Social Vulnerability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in social vulnerability\n",
    "social_vulnerability = pd.read_csv(\"data/social_vulnerability/SVI2018_US.csv\", dtype = {\"FIPS\": str, \"F_TOTAL\": float})\n",
    "\n",
    "# Subset and Rename columns\n",
    "social_vulnerability = social_vulnerability[[\"FIPS\", \"EP_MOBILE\", \"EP_SNGPNT\"]]\n",
    "social_vulnerability.columns = [\"GEOID\", \"mobile_homes\", \"single_parent_households\"]\n",
    "\n",
    "# Format GEOID column to have 11 digits, pad with 0s as necessary\n",
    "social_vulnerability[\"GEOID\"] = np.where(\n",
    "   social_vulnerability[\"GEOID\"].str.len() == 10,\n",
    "   \"0\" + social_vulnerability[\"GEOID\"],\n",
    "   social_vulnerability[\"GEOID\"]\n",
    ")\n",
    "\n",
    "social_vulnerability.to_csv(\"clean_data/non_energy/social_vulnerability.csv\", index = False)\n",
    "social_vulnerability.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eviction Data by County"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eviction = pd.read_csv(\n",
    "   \"data/eviction/county_proprietary_valid_2000_2018.csv\",\n",
    "   dtype = {\n",
    "      \"cofips\": str,\n",
    "      \"year\": int,\n",
    "      \"filing_rate\": float\n",
    "   }\n",
    "   )\n",
    "eviction = eviction[[\"cofips\", \"year\", \"filing_rate\"]]\n",
    "eviction_final = eviction.groupby([\"cofips\"], as_index = False).max(\"year\")\n",
    "# Test if there is 1 value for each county\n",
    "#eviction_final[[\"cofips\", \"year\"]].groupby([\"cofips\"], as_index = False).nunique()[\"year\"].unique()\n",
    "\n",
    "# Subset and Rename columns accordingly\n",
    "eviction_final = eviction_final[[\"cofips\", \"filing_rate\"]]\n",
    "eviction_final.columns = [\"county_GEOID\", \"filing_rate\"]\n",
    "\n",
    "# Format county GEOID properly - fill in zeros accordingly\n",
    "eviction_final[\"county_GEOID\"] = np.where(\n",
    "   eviction_final[\"county_GEOID\"].str.len() == 4,\n",
    "   \"0\" + eviction_final[\"county_GEOID\"],\n",
    "   eviction_final[\"county_GEOID\"]\n",
    ")\n",
    "\n",
    "# Split county_GEOID into STATEFP and COUNTYFP for overall join at the end\n",
    "eviction_final[\"STATEFP\"] = eviction_final[\"county_GEOID\"].str[:2]\n",
    "eviction_final[\"COUNTYFP\"] = eviction_final[\"county_GEOID\"].str[2:]\n",
    "eviction_final.pop(\"county_GEOID\")\n",
    "\n",
    "# Write out\n",
    "eviction_final.to_csv(\"clean_data/non_energy/eviction.csv\", index = False)\n",
    "eviction_final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning Energy Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File and Directory setup\n",
    "energy_dir = \"data/energy\"\n",
    "\n",
    "e_burden_dir = \"data/energy/doe_lead\"\n",
    "e_burden_outdir = \"clean_data/energy/doe_lead\"\n",
    "\n",
    "aceee_outdir = \"clean_data/energy\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Energy Burden\n",
    "\n",
    "Subsequent code blocks take the energy burden files downloaded from the DOE LEAD tool remove unnecesarily rows and compile them together into one CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_burden_files = os.listdir(e_burden_dir)\n",
    "\n",
    "# Remove any unwanted files\n",
    "e_burden_files = [filename for filename in e_burden_files if re.match(r\"(?:[A-Z])(?:[A-Z])\\.csv\", filename)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-write Energy Burden files\n",
    "for e_burden_filename in e_burden_files:\n",
    "   # Read in current file\n",
    "   curr_fp = os.path.join(e_burden_dir, e_burden_filename)\n",
    "   f = open(curr_fp, \"r\")\n",
    "   lines = f.readlines()\n",
    "   f.close()\n",
    "\n",
    "   # Remove rows of DOE LEAD Energy burden files (metadata, description)\n",
    "   lines = lines[8:]\n",
    "\n",
    "   # Write file back without description rows\n",
    "   out_fp = os.path.join(e_burden_outdir, e_burden_filename)\n",
    "   f_out = open(out_fp, \"w\")\n",
    "   f_out.writelines(lines)\n",
    "   f_out.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Compile all Energy Burden files together\n",
    "\n",
    "# Energy Burden dataframe (collector)\n",
    "e_burden = pd.DataFrame(data = None, columns = [\"GEOID\", \"energy_burden\"])\n",
    "\n",
    "for e_burden_filename in e_burden_files:\n",
    "   curr_fp = os.path.join(e_burden_outdir, e_burden_filename)\n",
    "   curr_df = pd.read_csv(curr_fp, dtype={\"Geography ID\": str})\n",
    "\n",
    "   # Format current dataframe\n",
    "   curr_df = curr_df[[\"Geography ID\", \"Avg. Energy Burden (% income)\"]]\n",
    "   curr_df.columns = [\"GEOID\", \"energy_burden\"]\n",
    "   curr_df[\"GEOID\"] = np.where(\n",
    "      curr_df[\"GEOID\"].str.len() == 10,\n",
    "      '0' + curr_df[\"GEOID\"],\n",
    "      curr_df[\"GEOID\"]\n",
    "   )\n",
    "\n",
    "   # Collect current \n",
    "   e_burden = pd.concat([e_burden, curr_df])\n",
    "\n",
    "e_burden[\"energy_burden\"] = np.where(\n",
    "   e_burden[\"energy_burden\"] > 100.0,\n",
    "   100.0,\n",
    "   e_burden[\"energy_burden\"]\n",
    ")\n",
    "\n",
    "# Writing Energy burden dataframe\n",
    "e_burden.to_csv(os.path.join(\"clean_data/energy\", \"energy_burden.csv\"), index = False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ACEEE State Scorecard Variables\n",
    "\n",
    "**Note:** ACEEE State Scorecard Variables are reported at a state level, and so each the state level score was broadcasted and assigned to be the score for each census tract of their respective state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aceee = pd.read_csv(os.path.join(energy_dir, \"ACEEE State Scorecard Data, 2021.csv\"))\n",
    "\n",
    "# Capturing correct columns\n",
    "aceee = aceee[[\n",
    "   \"STATE\",\n",
    "   \"GAS \\nSAVINGS - % \\nof retail residential and commercial sales\",\n",
    "   \"ELECTRIC SAVINGS - % \\nof retail sales\"\n",
    "   ]]\n",
    "aceee.columns = [\"STATE\", \"gas_savings_percent\", \"electric_savings_percent\"]\n",
    "\n",
    "# Getting rid of excess empty rows\n",
    "aceee = aceee.iloc[2:53]\n",
    "\n",
    "# Add their state fips code\n",
    "state_fips = pd.read_csv(\"data/support/state_fips.csv\", dtype = {\"STATE\": str})\n",
    "state_fips = state_fips[[\"STATE_NAME\", \"STATE\"]]\n",
    "state_fips.columns = [\"STATE\", \"STATEFP\"]\n",
    "aceee = pd.merge(aceee, state_fips, how = \"left\", on = \"STATE\")\n",
    "\n",
    "# Remove $ and % signs\n",
    "aceee[\"gas_savings_percent\"] = aceee[\"gas_savings_percent\"].str[:-1]\n",
    "aceee[\"electric_savings_percent\"] = aceee[\"electric_savings_percent\"].str[:-1]\n",
    "\n",
    "# Make sure all columns are correct types\n",
    "aceee = aceee.astype({\n",
    "   \"STATE\": str,\n",
    "   \"STATEFP\": str,\n",
    "   \"gas_savings_percent\": float,\n",
    "   \"electric_savings_percent\": float\n",
    "})\n",
    "\n",
    "# Write ACEEE data\n",
    "aceee.to_csv(os.path.join(aceee_outdir, \"aceee.csv\"), index = False)\n",
    "aceee.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Home Energy Affordability Gap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_affordability = pd.read_csv(\"data/energy/Home Energy Affordability Gap by county (2021).csv\")\n",
    "\n",
    "# Get average shortfall / LI HH for households below 200% of FPL\n",
    "e_affordability = e_affordability.iloc[2:3145, [2, 95]]\n",
    "e_affordability.columns = [\"county_GEOID\", \"avg_shortfall_usd\"]\n",
    "\n",
    "\n",
    "# Process columns\n",
    "e_affordability = e_affordability.astype({\n",
    "   \"county_GEOID\": str,\n",
    "   \"avg_shortfall_usd\": str\n",
    "})\n",
    "# Fill county_geoid (= statefp + countyfp) with zeros if necessary\n",
    "e_affordability[\"county_GEOID\"] = np.where(\n",
    "   e_affordability[\"county_GEOID\"].str.len() == 4,\n",
    "   \"0\" + e_affordability[\"county_GEOID\"],\n",
    "   e_affordability[\"county_GEOID\"]\n",
    ")\n",
    "\n",
    "# Format avg_shortfall_usd from str format to float\n",
    "e_affordability[\"avg_shortfall_usd\"] = e_affordability[\"avg_shortfall_usd\"].str[1:]\n",
    "e_affordability[\"avg_shortfall_usd\"] = e_affordability[\"avg_shortfall_usd\"].str.replace(\",\", \"\", regex = False)\n",
    "e_affordability[\"avg_shortfall_usd\"] = e_affordability[\"avg_shortfall_usd\"].str.replace(\"DIV/0!\", \"NaN\", regex = False)\n",
    "e_affordability = e_affordability.astype({\"avg_shortfall_usd\": float})\n",
    "e_affordability = e_affordability.fillna(-999)\n",
    "\n",
    "# Split county_GEOID into STATEFP and COUNTYFP for overall join at the end\n",
    "e_affordability[\"STATEFP\"] = e_affordability[\"county_GEOID\"].str[:2]\n",
    "e_affordability[\"COUNTYFP\"] = e_affordability[\"county_GEOID\"].str[2:]\n",
    "e_affordability.pop(\"county_GEOID\")\n",
    "\n",
    "# Write out\n",
    "e_affordability.to_csv(\"clean_data/energy/home_energy_affordability_gap.csv\", index = False)\n",
    "e_affordability.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Community Power Scorecard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "community_power = pd.read_csv(\"data/energy/Community Power Scorecard & Methodology (2022).csv\")\n",
    "community_power = community_power.iloc[:51, [1, 14]]\n",
    "community_power.columns = [\"STATE\", \"total_percent_score\"]\n",
    "\n",
    "# Renaming Washington DC for STATEFP join\n",
    "community_power[\"STATE\"] = np.where(\n",
    "   community_power[\"STATE\"].str[:] == \"Washington D.C.\",\n",
    "   \"District of Columbia\",\n",
    "   community_power[\"STATE\"]\n",
    ")\n",
    "\n",
    "# Add their state fips code\n",
    "state_fips = pd.read_csv(\"data/support/state_fips.csv\", dtype = {\"STATE\": str})\n",
    "state_fips = state_fips[[\"STATE_NAME\", \"STATE\"]]\n",
    "state_fips.columns = [\"STATE\", \"STATEFP\"]\n",
    "community_power = pd.merge(community_power, state_fips, how = \"left\", on = \"STATE\")\n",
    "\n",
    "community_power.to_csv(\"clean_data/energy/community_power_scorecard.csv\", index = False)\n",
    "community_power"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Median income of solar installers by tract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solar_installers = pd.read_csv(\"data/energy/Median income of solar installers by tract.csv\", dtype = {\"CensusTract\": str, \"n\": int, \"median_income\": float})\n",
    "solar_installers.columns = [\"GEOID\", \"num_solar_installers\", \"median_income_solar\"]\n",
    "\n",
    "# Make sure all tract numbers are 11 digits long pad with zeros accordingly\n",
    "solar_installers[\"GEOID\"] = np.where(\n",
    "   solar_installers[\"GEOID\"].str.len() == 10,\n",
    "   \"0\" + solar_installers[\"GEOID\"],\n",
    "   solar_installers[\"GEOID\"]\n",
    ")\n",
    "\n",
    "solar_installers[\"median_income_solar\"] = solar_installers[\"median_income_solar\"] * 1000\n",
    "\n",
    "# Write file out\n",
    "solar_installers.to_csv(\"clean_data/energy/median_income_solar_installer.csv\", index = False)\n",
    "solar_installers.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Residential Rates as a % of Commercial and Industral rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_percent = pd.read_csv(\"data/energy/Residential cost per kWh as % of commercial + industrial rates.csv\")\n",
    "# Keep relevant columns and rows\n",
    "res_percent = res_percent.iloc[3:54, [0, 8]]\n",
    "# Rename columns\n",
    "res_percent.columns = [\"STATE\", \"res_rate_percent_commercial_industrial\"]\n",
    "# Make sure column types are correct\n",
    "res_percent = res_percent.astype({\n",
    "   \"STATE\": str,\n",
    "   \"res_rate_percent_commercial_industrial\": str\n",
    "})\n",
    "\n",
    "# Remove % sign from residential rates and cast as float\n",
    "res_percent[\"res_rate_percent_commercial_industrial\"] = res_percent[\"res_rate_percent_commercial_industrial\"].str[:-1]\n",
    "res_percent = res_percent.astype({\"res_rate_percent_commercial_industrial\": float})\n",
    "\n",
    "# Add their state fips code\n",
    "state_fips = pd.read_csv(\"data/support/state_fips.csv\", dtype = {\"STATE\": str})\n",
    "state_fips = state_fips[[\"STATE_NAME\", \"STATE\"]]\n",
    "state_fips.columns = [\"STATE\", \"STATEFP\"]\n",
    "res_percent = pd.merge(res_percent, state_fips, how = \"left\", on = \"STATE\")\n",
    "\n",
    "# Write results out\n",
    "res_percent.to_csv(\"clean_data/energy/res_rate_percent_commercial_industrial.csv\", index = False)\n",
    "res_percent.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine all variables into one output file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use census tract metadata file as base dataframe for joins\n",
    "# Taken from: https://www.census.gov/geographies/mapping-files/time-series/geo/cartographic-boundary.html\n",
    "eep = gpd.read_file(\"clean_data/cb_2021_us_tract_500k_filtered_simplified.json\", dtype = {\n",
    "   \"STATEFP\": str,\n",
    "   \"COUNTYFP\": str,\n",
    "   \"TRACTCE\": str,\n",
    "   \"GEOID\": str\n",
    "})\n",
    "\n",
    "unwanted_states = [\n",
    "\t\"60\", # American Samoa\n",
    "  \"66\", # Guam\n",
    "  \"69\", # Northern Mariana Islands\n",
    "  \"72\", # Puerto Rico\n",
    "  \"78\", # Virgin Islands\n",
    "  \"15\", # Hawaii\n",
    "  \"02\",  # Alaska\n",
    "]\n",
    "\n",
    "eep = eep[~eep.STATEFP.isin(unwanted_states)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tables containing variables that will be joined\n",
    "energy_burden = pd.read_csv(\"clean_data/energy/energy_burden.csv\", dtype = {\n",
    "   \"GEOID\": str,\n",
    "   \"energy_burden\": float\n",
    "})\n",
    "\n",
    "aceee = pd.read_csv(\"clean_data/energy/aceee.csv\", dtype = {\n",
    "   \"STATE\": str,\n",
    "   \"gas_savings_percent\": float,\n",
    "   \"electric_savings_percent\": float,\n",
    "   \"STATEFP\": str\n",
    "})\n",
    "\n",
    "e_affordability = pd.read_csv(\"clean_data/energy/home_energy_affordability_gap.csv\", dtype = {\n",
    "   \"avg_shortfall_usd\": float,\n",
    "   \"STATEFP\": str,\n",
    "   \"COUNTYFP\": str\n",
    "})\n",
    "\n",
    "community_power = pd.read_csv(\"clean_data/energy/community_power_scorecard.csv\", dtype = {\n",
    "   \"STATEFP\": str,\n",
    "   \"total_percent_score\": float\n",
    "})\n",
    "community_power.pop(\"STATE\")\n",
    "community_power = community_power.rename(columns = {\"total_percent_score\": \"community_power_score\"})\n",
    "\n",
    "eviction = pd.read_csv(\"clean_data/non_energy/eviction.csv\", dtype = {\n",
    "   \"filing_rate\": float,\n",
    "   \"STATEFP\": str,\n",
    "   \"COUNTYFP\": str\n",
    "})\n",
    "\n",
    "res_percent = pd.read_csv(\"clean_data/energy/res_rate_percent_commercial_industrial.csv\", dtype = {\n",
    "   \"STATE\": str,\n",
    "   \"res_rate_percent_commercial_industrial\": float,\n",
    "   \"STATEFP\": str\n",
    "})\n",
    "res_percent = res_percent[[\"STATEFP\", \"res_rate_percent_commercial_industrial\"]]\n",
    "\n",
    "solar_installers = pd.read_csv(\"clean_data/energy/median_income_solar_installer.csv\", dtype = {\n",
    "   \"GEOID\": str,\n",
    "   \"num_solar_installers\": int,\n",
    "   \"median_income_solar\": float\n",
    "})\n",
    "\n",
    "climate_vulnerability = pd.read_csv(\"clean_data/non_energy/climate_vulnerability.csv\", dtype = {\n",
    "   \"GEOID\": str,\n",
    "   \"climate_score\": float,\n",
    "   \"climate_rating\": str\n",
    "})\n",
    "\n",
    "social_vulnerability = pd.read_csv(\"clean_data/non_energy/social_vulnerability.csv\", dtype = {\n",
    "   \"GEOID\": str,\n",
    "   \"svi\": float\n",
    "})\n",
    "\n",
    "acs = pd.read_csv(\"clean_data/non_energy/acs.csv\", dtype = {\n",
    "   \"total_pop\": float,\n",
    "   \"GEOID\": str,\n",
    "   \"year_built\": float,\n",
    "   \"internet_access\": float,\n",
    "   \"total_households\": int,\n",
    "   \"labor_force_rate\": float,\n",
    "   \"insured\": float,\n",
    "   \"seniors_living_alone\": float,\n",
    "   \"median_income\": float,\n",
    "   \"owner_occupied\": float,\n",
    "   \"renter_occupied\": float,\n",
    "   \"disabled\": float,\n",
    "   \"bipoc_percent\": float,\n",
    "   \"no_hs\": float\n",
    "})\n",
    "acs = acs[[\n",
    "   \"total_pop\",\n",
    "   \"GEOID\",\n",
    "   \"year_built\",\n",
    "   \"internet_access\",\n",
    "   \"total_households\",\n",
    "   \"labor_force_rate\",\n",
    "   \"insured\",\n",
    "   \"seniors_living_alone\",\n",
    "   \"median_income\",\n",
    "   \"owner_occupied\",\n",
    "   \"renter_occupied\",\n",
    "   \"disabled\",\n",
    "   \"bipoc_percent\",\n",
    "   \"no_hs\"\n",
    "]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join variables to the data\n",
    "eep_final = eep.merge(energy_burden, how = \"left\", on = \"GEOID\")\n",
    "eep_final = eep_final.merge(aceee, how = \"left\", on = \"STATEFP\")\n",
    "eep_final = eep_final.merge(res_percent, how = \"left\", on = \"STATEFP\")\n",
    "eep_final = eep_final.merge(solar_installers, how = \"left\", on = \"GEOID\")\n",
    "eep_final = eep_final.merge(climate_vulnerability, how = \"left\", on = \"GEOID\")\n",
    "eep_final = eep_final.merge(social_vulnerability, how = \"left\", on = \"GEOID\")\n",
    "eep_final = eep_final.merge(acs, how = \"left\", on = \"GEOID\")\n",
    "eep_final = eep_final.merge(community_power, how = \"left\", on = \"STATEFP\")\n",
    "eep_final = eep_final.merge(e_affordability, how = \"left\", on = [\"STATEFP\", \"COUNTYFP\"])\n",
    "eep_final = eep_final.merge(eviction, how = \"left\", on = [\"STATEFP\", \"COUNTYFP\"])\n",
    "\n",
    "eep_final = eep_final.replace(-999, np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write overall EEP file out (as GeoJSON)\n",
    "eep_final.to_file(\"clean_data/eep_final_simplified.json\", driver = \"GeoJSON\")\n",
    "eep_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write EEP data as shapefile\n",
    "eep_final.to_file(\"clean_data/eep_final_simplified/eep_final_simplified.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write out just EEP data as CSV (no geometry for maps)\n",
    "eep_data = eep[eep.columns.drop(['geometry'])]\n",
    "eep_data.to_csv(\"clean_data/eep_final_data.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
